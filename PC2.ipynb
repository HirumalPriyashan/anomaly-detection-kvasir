{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dn-6c02VmqiN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import numpy as nAp\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_DIR = \"D:/Campus/4 Sem Files/Programming Challenge II - CS2212/\"\n",
    "DATASET_DIR = \"D:/Campus/4 Sem Files/Programming Challenge II - CS2212/kvasir-dataset-v2/\"\n",
    "SOURCE_DIR = \"D:/Campus/4 Sem Files/programming Challenge II - CS2212/dataset/\"\n",
    "WEIGHTS_DIR = \"D:/Campus/4 Sem Files/programming Challenge II - CS2212/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Campus\\4 Sem Files\\Programming Challenge II - CS2212\n",
      "D:\\Campus\\4 Sem Files\\Programming Challenge II - CS2212/kvasir-dataset-v2.zip\n"
     ]
    }
   ],
   "source": [
    "#change the current working directory\n",
    "os.chdir(ZIP_DIR)\n",
    "path_dataset = getcwd()\n",
    "print(path_dataset)\n",
    "path_dataset = f\"{getcwd()}/kvasir-dataset-v2.zip\"\n",
    "print(path_dataset)\n",
    "\n",
    "# #Delete the folders if they already exist\n",
    "if os.path.exists(DATASET_DIR) and os.path.isdir(DATASET_DIR):\n",
    "    shutil.rmtree(DATASET_DIR)\n",
    "\n",
    "if os.path.exists(SOURCE_DIR) and os.path.isdir(SOURCE_DIR):\n",
    "    shutil.rmtree(SOURCE_DIR)\n",
    "\n",
    "local_zip = path_dataset\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(ZIP_DIR)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists(SOURCE_DIR)) or not (os.path.isdir(SOURCE_DIR)):\n",
    "    os.mkdir(SOURCE_DIR)\n",
    "    os.mkdir(SOURCE_DIR + \"/training\")\n",
    "    os.mkdir(SOURCE_DIR + \"/testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', 'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis']\n"
     ]
    }
   ],
   "source": [
    "labels = os.listdir(DATASET_DIR)\n",
    "print(labels)\n",
    "\n",
    "for label in labels:\n",
    "    test_path = SOURCE_DIR+ \"/training/\"+label\n",
    "    train_path = SOURCE_DIR + \"/testing/\"+label\n",
    "\n",
    "    if not (os.path.exists(train_path)) or not (os.path.isdir(train_path)):\n",
    "        os.mkdir(train_path)\n",
    "\n",
    "    if not (os.path.exists(test_path)) or not (os.path.isdir(test_path)):\n",
    "        os.mkdir(test_path)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gi3yD62a6X3S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dyed-lifted-polyps : 1000\n",
      "dyed-resection-margins : 1000\n",
      "esophagitis : 1000\n",
      "normal-cecum : 1000\n",
      "normal-pylorus : 1000\n",
      "normal-z-line : 1000\n",
      "polyps : 1000\n",
      "ulcerative-colitis : 1000\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label,end=\" : \")\n",
    "    print(len(os.listdir(DATASET_DIR+label)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvSODo0f9LaU"
   },
   "outputs": [],
   "source": [
    "#split the dataset into trianing and testing set according to split_size\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_RATIO):\n",
    "    labels = os.listdir(SOURCE)\n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        source_path = SOURCE + label +'/'\n",
    "        training_path = TRAINING + label +'/'\n",
    "        testing_path = TESTING + label +'/'\n",
    "        \n",
    "        data = os.listdir(source_path)\n",
    "        filtered_data = []\n",
    "        \n",
    "        for image in data:\n",
    "            if(os.path.getsize(source_path+image)):\n",
    "                filtered_data.append(image)\n",
    "\n",
    "        \n",
    "        random.sample(filtered_data,len(filtered_data))\n",
    "        train_set = filtered_data[:int(len(filtered_data)*SPLIT_RATIO)]\n",
    "        test_set  = filtered_data[int(len(filtered_data)*SPLIT_RATIO):]\n",
    "\n",
    "        for train_image in train_set:\n",
    "            copyfile(source_path + train_image,training_path + train_image)\n",
    "\n",
    "        for test_image in test_set:\n",
    "            copyfile(source_path + test_image,testing_path + test_image)\n",
    "\n",
    "\n",
    "TRAINING_DIR = SOURCE_DIR + \"/training/\"\n",
    "TESTING_DIR = SOURCE_DIR  + \"/testing/\"\n",
    "\n",
    "split_ratio = .75\n",
    "split_data(DATASET_DIR, TRAINING_DIR, TESTING_DIR, split_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luthalB76ufC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dyed-lifted-polyps\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "dyed-resection-margins\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "esophagitis\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "normal-cecum\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "normal-pylorus\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "normal-z-line\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "polyps\n",
      "train : 750\n",
      "test : 250\n",
      "\n",
      "ulcerative-colitis\n",
      "train : 750\n",
      "test : 250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label)\n",
    "    print(\"train\", end=\" : \")\n",
    "    print(len(os.listdir(SOURCE_DIR+ \"/training/\"+label)))\n",
    "    print(\"test\", end=\" : \")\n",
    "    print(str(len(os.listdir(SOURCE_DIR+ \"/testing/\"+label)))+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BQrav4anTmj"
   },
   "outputs": [],
   "source": [
    "pre_trained_model = InceptionV3(input_shape = (224, 224, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(WEIGHTS_DIR)\n",
    "\n",
    "\n",
    "\n",
    "for layer in pre_trained_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "last_output = pre_trained_model.layers[-1].output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)                  \n",
    "x = layers.Dense  (8, activation='softmax')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlNjoJ5D61N6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 images belonging to 8 classes.\n",
      "Found 2000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = SOURCE_DIR + \"/training/\"\n",
    "train_datagen = ImageDataGenerator(rescale =1.0/255,fill_mode='nearest', width_shift_range=0.2, height_shift_range=0.2,brightness_range= [0.4,1],shear_range=0.2,zoom_range= [0.8,1.4])\n",
    "\n",
    "    \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,batch_size = 32, class_mode='categorical',target_size = (224,224), )\n",
    "\n",
    "VALIDATION_DIR = SOURCE_DIR + \"/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale =1.0/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,batch_size = 32, class_mode='categorical',target_size = (224,224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 714s 4s/step - loss: 1.5103 - acc: 0.4580 - val_loss: 0.7533 - val_acc: 0.7255\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 753s 4s/step - loss: 1.0467 - acc: 0.6078 - val_loss: 0.6129 - val_acc: 0.7615\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 799s 4s/step - loss: 0.9286 - acc: 0.6527 - val_loss: 0.5372 - val_acc: 0.7950\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 691s 4s/step - loss: 0.8985 - acc: 0.6665 - val_loss: 0.4663 - val_acc: 0.8185\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 728s 4s/step - loss: 0.8265 - acc: 0.6887 - val_loss: 0.4729 - val_acc: 0.8185\n",
      "Epoch 6/50\n",
      "113/188 [=================>............] - ETA: 3:53 - loss: 0.7953 - acc: 0.7008"
     ]
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "history = model.fit(train_generator,\n",
    "                              epochs=50,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks = [callbacks]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyS4n53w7DxC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWZrJN4-65RC"
   },
   "outputs": [],
   "source": [
    "# PLOT LOSS AND ACCURACY\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 6 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "uAPOR",
   "launcher_item_id": "e9lTb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
